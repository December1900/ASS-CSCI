df <- read.csv("income.csv")
head(df)
modelA <- lm(Age ~ Gender, data=df)
summary(modelA)
modelA <- lm(Age ~ Education + Gender, data=df)
modelA <- lm(Age ~ Education + Gender, data=df)
summary(modelA)
modelA <- lm(Age ~ Education + Gender, data=df)
summary(modelA)
modelB <- lm(Age ~ Education, data=df)
summary(modelB)
modelA <- lm(Income ~ Age + Education + Gender, data=df)
summary(modelA)
modelB <- lm(Income ~ Age + Education, data=df)
summary(modelB)
item <- data.frame(41, 12)
prediction <- predict(modelB, item)
summary(modelB)
item <- data.frame({41, 12})
prediction <- predict(modelB, item)
item <- data.frame(Age=41, Education=12)
prediction <- predict(modelB, item)
prediction <- predict(modelB, item)
prediction
library(plyr)
library(ggplot2)
library(cluster)
library(lattice)
library(graphics)
library(grid)
library(gridExtra)
library(ggthemes)
library(Hmisc)
data("iris")
print(iris)
str(iris)
describe(iris)
#The summary of them are shown as below.
summary(iris)
#the scatterplot matrix between the four attributes
iris_v=iris[,-5]
plot(iris_v)
#create a new variable ??new?? to store the data Iris which could help me prepare the data
new <- iris
#clean the species in new which could let the dataset form in one format
new <- new[,-5]
print(new)
#k means the K value.
wss <- numeric(15)
for(k in 1:15){
wss[k] <- sum(kmeans(new, k, nstart=25)$withinss)
}
print(wss)
#this plot could help me find the K value.
plot(1:15, wss,type='b', xlab="number of cluster", ylab="within sum of squares")
km <- kmeans(new,3, nstart = 25)
km
plot(new[c("Sepal.Length", "Sepal.Width")], col =km$cluster )
#plot of petal with center
points(km$center, col=1:3, pch=8, cex=2)
plot(new[c("Petal.Length", "Petal.Width")], col =km$cluster)
points(km$center, col=1:3, pch=8, cex=2)
#separate the sepal and petal, classify them independently
km <- kmeans(new[,1:2],3, nstart = 25)
km
plot(new[c("Sepal.Length", "Sepal.Width")], col =km$cluster )
points(km$center, col=1:3, pch=8, cex=2)
km <- kmeans(new,3, nstart = 25)
km
#separate the sepal and petal, classify them independently
km <- kmeans(new[,3:4],3, nstart = 25)
km
plot(new[c("Petal.Length", "Petal.Width")], col =km$cluster)
points(km$center, col=1:3, pch=8, cex=2)
#use a two-dimension array to store data
Sepal.Length <- new[,1]
Sepal.Length
#use a two-dimension array to store data
Sepal.width <- new[,2]
Sepal.width
#preparation for the HA algorithm. create a 2-dimension array.
distancearray=cbind(Sepal.Length,Sepal.width)
distancearray
#change the value into euclidean distance.
out.dist=dist(distancearray,method="euclidean")
#h cluaster by mcquitty(can use ??median??,??single??, ??complete??)
out.hclust=hclust(out.dist,method="mcquitty")
#draw the plot as well
plot(out.hclust)
#based on the previous plot,seperate the class with squares and show it
rect.hclust(out.hclust,k=3)
#use a two-dimension array to store data
Petal.Length <- new[,3]
Petal.Length
#use a two-dimension array to store data
Petal.Width <- new[,4]
#use a two-dimension array to store data
Petal.Width <- new[,4]
#use a two-dimension array to store data
Petal.Width <- new[,4]
#use a two-dimension array to store data
Petal.Width <- new[,4]
Petal.Width
#preparation for the HA algorithm. create a 2-dimension array.
distancearray=cbind(Petal.Length,Petal.Width)
distancearray
#change the value into euclidean distance.
out.dist=dist(distancearray,method="euclidean")
#h cluaster by mcquitty(can use ??median??,??single??, ??complete??)
out.hclust=hclust(out.dist,method="mcquitty")
#draw the plot as well
plot(out.hclust)
#based on the previous plot,seperate the class with squares and show it
rect.hclust(out.hclust,k=3)
prediction
prediction <- predict(modelB, item)
summary(prediction)
prediction
=
# compute confidence interval
ci <- predict(modelB, item, interval = "confidence")
ci
# compute the prediction interval
pi <- predict(modelB, item, interval = "prediction")
pi
df <- read.csv("churn.csv")
head(df)
modelA <- lm(Income ~ Age + Education + Gender, data=df)
summary(modelA)
modelB <- lm(Income ~ Age + Education, data=df)
summary(modelB)
item <- data.frame(Age=41, Education=12)
source('~/Desktop/Week6/task1.R', echo=TRUE)
prediction <- predict(modelC)
head(df)
modelA <- lm(Churned ~ Age + Married + Cust_years + Churned_contacts, data = df)
summary(modelA)
modelB <- lm(Churned ~ Age + Married + Churned_contacts, data = df)
summary(modelB)
modelC <- lm(Churned ~ Age + Churned_contacts, data = df)
df <- read.csv("churn.csv")
head(df)
modelA <- lm(Churned ~ Age + Married + Cust_years + Churned_contacts, data = df)
summary(modelA)
modelB <- lm(Churned ~ Age + Married + Churned_contacts, data = df)
summary(modelB)
modelC <- lm(Churned ~ Age + Churned_contacts, data = df)
summary(modelC)
prediction <- predict(modelC)
data <- data.frame(prob=pre)
data <- data.frame(prob=prediction)
prediction <- predict(modelC)
data <- data.frame(prob=prediction, obs=df$Churned)
data <- data[order(data$prob),]
n <- nrow(data)
tpr <- fpr <- rep(0,n)
for (i in 1:n) {
threshold <- data$prob[i]
tp <- sum(data$prob > threshold & data$obs == 1)
fp <- sum(data$prob > threshold & data$obs == 0)
tn <- sum(data$prob < threshold & data$obs == 0)
fn <- sum(data$prob < threshold & data$obs == 1)
tpr[i] <- tp/(tp+fn)
fpr[i] <- fp/(tn+fp)
}
plot(fpr,tpr,type='l')
abline(a=0,b=1)
pred <- prediction(pre,df$Churned)
library(pROC)
library(pROC)
modelroc <- roc(df$Churned, prediction)
plot(modelroc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),
grid.col=c("green", "red"), max.auc.polygon=TRUE,
auc.polygon.col="skyblue", print.thres=TRUE)
library(ROCR)
pred <- prediction(prediction,df$Churned)
performance(pred,'auc')@y.values
perf <- performance(pred,'tpr','fpr')
plot(perf)
plot(fpr,tpr,type='l')
pre <- predict(modelC, type='response')
# draw ROC
modelCroc <- roc(df$Churned, pre)
plot(modelCroc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),
grid.col=c("blue", "red"), max.auc.polygon=TRUE,
auc.polygon.col="skyblue", print.thres=TRUE)
# put the predicted probability prob and the actual result y in a data frame
data <- data.frame(prob=pre, obs=df$Churned)
# sort by predicted probability from low to high
data <- data[order(data$prob),]
n <- nrow(data)
tpr <- fpr <- rep(0,n)
for (i in 1:n) {
threshold <- data$prob[i]
tp <- sum(data$prob > threshold & data$obs == 1)
fp <- sum(data$prob > threshold & data$obs == 0)
tn <- sum(data$prob < threshold & data$obs == 0)
fn <- sum(data$prob < threshold & data$obs == 1)
tpr[i] <- tp/(tp+fn)
fpr[i] <- fp/(tn+fp)
}
plot(fpr,tpr,type='l')
abline(a=0,b=1)
modelA <- lm(Income ~ Age + Education + Gender, data=df)
df <- read.csv("income.csv")
head(df)
modelA <- lm(Income ~ Age + Education + Gender, data=df)
summary(modelA)
modelB <- lm(Income ~ Age + Education, data=df)
summary(modelB)
# make prediction
prediction <- predict(modelB, item)
prediction
# make prediction
prediction <- predict(modelB, item)
prediction
# compute the confidence interval
ci <- predict(modelB, item, interval = "confidence")
ci
# compute the prediction interval
pi <- predict(modelB, item, interval = "prediction")
pi
# make prediction
prediction <- predict(modelB, item)
prediction
# compute the confidence interval
ci <- predict(modelB, item, interval = "confidence")
ci
# compute the prediction interval
pi <- predict(modelB, item, interval = "prediction")
pi
# make prediction
prediction <- predict(modelB, item)
prediction
# compute the confidence interval
ci <- predict(modelB, item, interval = "confidence")
ci
# compute the prediction interval
pi <- predict(modelB, item, interval = "prediction")
pi
library(pROC)
df <- read.csv("churn.csv")
head(df)
modelA <- lm(Churned ~ Age + Married + Cust_years + Churned_contacts, data = df)
summary(modelA)
modelB <- lm(Churned ~ Age + Married + Churned_contacts, data = df)
modelC <- lm(Churned ~ Age + Churned_contacts, data = df)
summary(modelB)
modelC <- lm(Churned ~ Age + Churned_contacts, data = df)
summary(modelC)
plot(modelCroc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),
grid.col=c("blue", "red"), max.auc.polygon=TRUE,
auc.polygon.col="skyblue", print.thres=TRUE)
plot(modelCroc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),
grid.col=c("green", "red"), max.auc.polygon=TRUE,
auc.polygon.col="skyblue", print.thres=TRUE)
# put the predicted probability prob and the actual result y in a data frame
data <- data.frame(prob=pre, obs=df$Churned)
# draw ROC
modelCroc <- roc(df$Churned, pre)
plot(modelCroc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2),
grid.col=c("green", "red"), max.auc.polygon=TRUE,
auc.polygon.col="skyblue", print.thres=TRUE)
